{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6 - Unit Test Your Functions!\n",
    "\n",
    "Follow the instructions in the following notebook cell. You will be graded on:\n",
    "\n",
    "    - Whether your unit tests are passing\n",
    "    - The completion of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the stuff you need here: os, glob, natsort, numpy, matplotlib.pyplot, pandas:\n",
    "\n",
    "\n",
    "# example import, don't edit this.\n",
    "import sys\n",
    "sys.path.append('../')   # appending your project to python path\n",
    "\n",
    "# import the rest:  \n",
    "import os\n",
    "import glob\n",
    "import natsort\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data I/O:\n",
    "\n",
    "First, in the `utils.py` file from the `functions` folder, recreate the function to get all the `.csv` data files:\n",
    "\n",
    "```python\n",
    "def get_files(path_pattern):\n",
    "    Given a `path_pattern` describing the path to all your data files, sorts the matching data files in alphanumerical order and returns a list with all file paths.\n",
    "\n",
    "    Input: \n",
    "        path_pattern (list): Path to all data files as described by a wildcard (*)\n",
    "    Returns:\n",
    "        files (list): Alphanumerical sorted list of all data files matching your path_pattern description.\n",
    "```\n",
    "\n",
    "Import it using relative imports and use it in the following cells to load your data. Remember `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-816c69c4d063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#first import your utility function:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Provide the wildcard (*) string pattern for your data files:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "#first import your utility function:\n",
    "from functions.utils import get_files\n",
    "\n",
    "# Provide the wildcard (*) string pattern for your data files:\n",
    "data_dir = './data'\n",
    "data_files = '/*.csv' #all data files are in csv format and in data subfolder\n",
    "\n",
    "os.path.abspath('data_dir') \n",
    "data_pattern = os.path.abspath(data_dir) + data_files\n",
    "print(data_pattern)\n",
    "\n",
    "\n",
    "# Use your utilities function to read and return a list of sorted data files: \n",
    "data_files = get_files(data_pattern)\n",
    "print('There are {} data csv files in the data folder'.format(len(data_files)))\n",
    "\n",
    "print (data_files)\n",
    "data_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame:\n",
    "\n",
    "Use `pandas` to load your `.csv` file data and turn them into a `dataframe`, then display the first 5 entries of your `dataframe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-baeab9bf8c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#df.describe() describes your data with fluor valuemfi and df.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_files' is not defined"
     ]
    }
   ],
   "source": [
    "# read in your csv files, concatenate all the csv's one by one into columns, and replace empty entries with 0's \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.concat([pd.read_csv(f, usecols=['Value']) for f in data_files], axis=1).fillna(0)\n",
    "\n",
    "#df.describe() describes your data with fluor valuemfi and df.shape\n",
    "\n",
    "\n",
    "# assign column numbers to your data frame\n",
    "df.columns = np.arange(df.shape[1])\n",
    "\n",
    "# Show the first 5 entries of your dataframe:\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realign our dataframes so we match the peak fluorescent signals:\n",
    "\n",
    "In `functions.utils.py`, add the following functions:\n",
    "\n",
    " - `find_middle()` - find the middle index of input data column and returns it\n",
    " - `realign_data()` - Center data around maximum or center of shortest column, padding with 0's, returns 1) a new dataframe with realigned columns and 2) the amount each column was shifted\n",
    "\n",
    "In `tests` folder, create a file named `test_utils.py` and add the following unit tests functions:\n",
    "\n",
    " - `test_find_middle_even()` - \n",
    " - `test_find_middle_odd()` - \n",
    " - `test_realign_max()` - \n",
    "\n",
    "Use your terminal to test these functions with `pytest assignment/tests`. Once all your tests are passing, import the functions and use them in the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-44bddf4f6329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# realign your data around its maximum or center, whichever one you like better:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrealign_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_middle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_aligned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrealign_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"center\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "# realign your data around its maximum or center, whichever one you like better: \n",
    "from functions.utils import realign_data\n",
    "from functions.utils import find_middle\n",
    "df_aligned, shifts = realign_data(df, \"center\")\n",
    "\n",
    "print('My realigned data frame has shape {}'.format(df_aligned.shape))\n",
    "\n",
    "plt.plot(df_aligned.values)\n",
    "df_aligned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize signal and visualize:\n",
    "\n",
    "Now we can normalize each column between 0-1 using `scikitlearn`'s `minmaxscale` function and visualize them. <em> In your plots, properly label all axis and colorbars with appropriate name description and units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_aligned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1b9043728e2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m df_normalized = pd.DataFrame(0, index=df_aligned.index,\n\u001b[0m\u001b[1;32m      6\u001b[0m columns=df_aligned.columns)\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvals\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_aligned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_aligned' is not defined"
     ]
    }
   ],
   "source": [
    "# Normalize every column entry of your realigned dataframe:\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import pandas as pd\n",
    "\n",
    "df_normalized = pd.DataFrame(0, index=df_aligned.index,\n",
    "columns=df_aligned.columns)\n",
    "for column,vals in df_aligned.iteritems():\n",
    "    event_id = df_aligned.index[df_aligned[column] != 0].tolist()\n",
    "    df_normalized.loc[event_id, column] = minmax_scal(df_aligned.loc[event_id,\n",
    "column].values)\n",
    "\n",
    "# pre-allocate an empty dataframe of 0's to be filled with normalized values, the index and column of this dataframe will be the same as the df_aligned dataframe:\n",
    "#df_normalized = \n",
    "\n",
    "# fill in the `df_normalized` dataframe with normalized columns:\n",
    "for column, vals in df_aligned.iteritems():\n",
    "    # find the indices of the column that are not 0, only normalize those:\n",
    "    ind = df_aligned.index[df_aligned[column]!=0].tolist()\n",
    "    # Normalize of those:\n",
    "    #df_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_aligned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4b2b71fcca72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use matplotlib to plot all the fluorescent signals:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_aligned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_aligned' is not defined"
     ]
    }
   ],
   "source": [
    "# Use matplotlib to plot all the fluorescent signals:\n",
    "plt.plot(df_aligned.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now instead of all signals, plot the average signal:\n",
    "# use numpy to find the mean first:\n",
    "mean_signal = np.zeros(df_aligned.shape[0])\n",
    "for index, row in df_aligned.iterrows():\n",
    "    val = row[row != 0] \n",
    "    mean_signal[index] = np.mean(val)\n",
    "\n",
    "#plot\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally visualize your aligned, and normalized fluorescent data in a heatmap:\n",
    "plt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:\n",
    "\n",
    "Repeat the analysis, but instead of realigning the fluorescent signals to it's maximum peaks. Modify the `realign_data` function so that it requires a second input named `aligned`. In the function, if `align == \"max\"`, the code executes the max peak alignment like before.\n",
    "\n",
    "But if `align == \"center\"`, the function will find the mid point of `input_data[column ! = 0]`, the middle index of non-zero values. Then shifts the values according to the new criteria.\n",
    "\n",
    "After adding this feature to `functions.utils.realign_data`, write the appropriate test for this new feature in `tests.test_utils.py`, make sure this test is passing. Then implement the new alignment and revisualize the results, again making sure all axis and colorbars are properly labeled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply your new realignment here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all of the newly aligned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the mean of the newly aligned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, push your submission branch, the `pytests` should automatically be executed upon your push. Make sure these tests are passing! Again, add me as a collaborator, and a reviewer in your pull request that merges `submission` into `main`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytest3",
   "language": "python",
   "name": "pytest3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
